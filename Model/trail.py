import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import pickle
import warnings

warnings.filterwarnings("ignore")

def sanitization(web):
    web = web.lower()
    token = []
    dot_token_slash = []
    raw_slash = str(web).split('/')
    for i in raw_slash:
        raw1 = str(i).split('-')
        slash_token = []
        for j in range(0, len(raw1)):
            raw2 = str(raw1[j]).split('.')
            slash_token = slash_token + raw2
        dot_token_slash = dot_token_slash + raw1 + slash_token
    token = list(set(dot_token_slash))
    if 'com' in token:
        token.remove('com')
    return token

def load_model(file_path):
    with open(file_path, 'rb') as file:
        model = pickle.load(file)
    return model

def load_vectorizer(file_path):
    with open(file_path, 'rb') as file:
        vectorizer = pickle.load(file)
    return vectorizer

def predict_url(models, vectorizers, weights, url):
    predictions = []
    for model, vectorizer, weight in zip(models, vectorizers, weights):
        if vectorizer is not None:
            x = vectorizer.transform([url])
        else:
            x = [url]  # No vectorizer for Random Forest model
        prediction = model.predict(x)[0]
        predictions.append((prediction, weight))
    return max(set(predictions), key=predictions.count)[0]

def main():
    # User Input
    url_to_check = input("Input the URL that you want to check (e.g., google.com): ")
    
    # Whitelist
    whitelist = [
        'hackthebox.eu',
        'root-me.org',
        # ... (other domains in the whitelist)
    ]

    # Filtering URL
    if url_to_check in whitelist:
        prediction = 'good'
    else:
        # Loading Models and Vectorizers
        lgr_model_path = "Classifier/pickel_model_lgr.pkl"
        rf_model_path = "Classifier/pickel_model_nb.pkl"
        lgr_vectorizer_path = "Classifier/pickel_vector.pkl"
        
        lgr_model = load_model(lgr_model_path)
        rf_model = load_model(rf_model_path)
        lgr_vectorizer = load_vectorizer(lgr_vectorizer_path)

        # Assigning Weights
        lgr_weight = 0.5
        rf_weight = 0.5

        # Predicting
        models = [lgr_model, rf_model]
        vectorizers = [lgr_vectorizer, None]  # None for Random Forest model
        weights = [lgr_weight, rf_weight]
        prediction = predict_url(models, vectorizers, weights, url_to_check)

    # Display Result
    print(f"\nThe entered domain is: {prediction}")

    if prediction != 'good':
        print("\nIf you feel that this prediction is wrong or are unsure about the output, you can contact us at harshith007varma007@gmail.com or pannag2003@gmail.com. We'll check the URL and update the model accordingly. Thank you.")

if __name__ == "__main__":
    main()

warnings.resetwarnings()
