import re
from urllib.parse import urlparse
import pandas as pd
import pickle
import warnings
from urllib.parse import urlparse
import re
from rich.console import Console
import os 
from dotenv import load_dotenv
from CORE.API_Scans import check_virustotal, urlscan_scan, check_abuse_ip_db
from CORE.Redirects_check import check_redirects
from CORE.Basic_Checks import *
load_dotenv()
virus_total_api_key = os.getenv("VIRUS_TOTAL_API_KEY")
urlscan_api_key = os.getenv("URLSCAN_API_KEY")
abuseip_api_key = os.getenv("ABUSEIP_API_KEY")




def sanitization(web):
    web = web.lower()
    tokens = set()
    raw_tokens = set()

    for part in web.split('/'):
        raw_tokens.update(part.split('-'))
        raw_tokens.update(part.split('.'))

    tokens.update(raw_tokens)
    tokens.discard('com')

    return list(tokens)

def load_model(file_path):
    with open(file_path, 'rb') as file:
        model = pickle.load(file)
    return model

def load_vectorizer(file_path):
    with open(file_path, 'rb') as file:
        vectorizer = pickle.load(file)
    return vectorizer

def predict_url(model, vectorizer, url):
    x = vectorizer.transform([url])
    prediction = model.predict(x)[0]
    return prediction

def predict(url_to_check):
    warnings.filterwarnings("ignore")

    

    # Whitelist
    whitelist=open("./file.txt",'r').readlines()

    # Filtering URL
    if url_to_check in whitelist:
        prediction = 'good'
    else:
        # Loading Model and Vectorizer
        model_path = "Classifier/pickel_model_lgr.pkl"
        vectorizer_path = "Classifier/pickel_vector.pkl"
        lgr_model = load_model(model_path)
        tfidf_vectorizer = load_vectorizer(vectorizer_path)

        # Predicting
        prediction = predict_url(lgr_model, tfidf_vectorizer, url_to_check)

    warnings.resetwarnings()
    return prediction
    
def is_malicious_url(url):
    console=Console()
    console.print("[*] Analyzing the URL...\n")

    # Parse the URL
    parsed_url = urlparse(url)

    prediction = predict(url)
    prediction_label =   '[green3]GOOD[/green3]'  if prediction == 'good' else  '[red3]MALICIOUS[/red3]' 
    console.print(f"[red3][-][/red3] The entered domain is: {prediction_label} according to our model.")
    if prediction != 'good':
        console.print("[green3][-][/green3] If you feel that this prediction is wrong or are unsure about the output, you can contact us at harshith007varma007@gmail.com or pannag2003@gmail.com. We'll check the URL and update the model accordingly. Thank you.")

    console.print(f"[gold1]-------------------------------------------------------[/gold1]")
    console.print(f"[gold1][!][/gold1] Starting virustotal scan...")
    check_virustotal(url, virus_total_api_key)
    console.print(f"[gold1]-------------------------------------------------------[/gold1]")
    console.print(f"[gold1][!][/gold1] Starting urlscan scan...")
    urlscan_scan(url, urlscan_api_key)
    console.print(f"[gold1]-------------------------------------------------------[/gold1]")
    console.print(f"[gold1][!][/gold1] Starting abuseIP scan...")
    check_abuse_ip_db(url, abuseip_api_key)
    console.print(f"[gold1]-------------------------------------------------------[/gold1]")

    # Check for phishing keywords
    potential_typosquatting_urls = check_typosquatting("file.txt", url)

    if potential_typosquatting_urls:
        console.print("[red3][+][/red3] Potential typosquatting URLs found:")
        for entry in potential_typosquatting_urls:
            console.print(f"    - URL: {entry['url']} (Similarity: {entry['similarity']:.2f})")
    else:
        console.print("[green3][-][/green3] No potential typosquatting URLs found.")
    console.print(f"[gold1]-------------------------------------------------------[/gold1]")    
    phishing_keywords = ['login', 'password', 'account', 'verify', 'secure']
    phishing_result = any(keyword in parsed_url.path.lower() for keyword in phishing_keywords)
    console.print(f"[green3][-][/green3] Phishing keywords check: {'Detected' if phishing_result else 'Not detected'}")
    console.print(f"[gold1]-------------------------------------------------------[/gold1]")
    # Check for IP address in the URL
    ip_result = bool(re.match(r'\d+\.\d+\.\d+\.\d+', parsed_url.netloc))
    console.print(f"[green3][-][/green3] IP address check: {'Detected' if ip_result else 'Not detected'}")
    console.print(f"[gold1]-------------------------------------------------------[/gold1]")
    # Check for non-standard ports
    port_result = parsed_url.port and parsed_url.port not in [80, 443]
    console.print(f"[green3][-][/green3] Non-standard ports check: {'Detected' if port_result else 'Not detected'}")
    console.print(f"[gold1]-------------------------------------------------------[/gold1]")
    # Check for unusual URL structure
    structure_result = check_unusual_structure(parsed_url.path)
    console.print(f"[green3][-][/green3] Unusual URL structure check: {'Detected' if structure_result else 'Not detected'}")
    console.print(f"[gold1]-------------------------------------------------------[/gold1]")
    # Check for redirect chains
    check_redirects(url)
    console.print(f"[gold1]-------------------------------------------------------[/gold1]")
    # Check for HTTPS usage anomalies
    https_anomalies_result = check_https_anomalies(url)
    console.print(f"[green3][-][/green3] HTTPS anomalies check: {'Detected' if https_anomalies_result else 'Not detected'}")
    console.print(f"[gold1]-------------------------------------------------------[/gold1]")
    # Check for dynamic parameters
    dynamic_params_result = check_dynamic_parameters(parsed_url.query)
    console.print(f"[green3][-][/green3] Dynamic parameters check: {'Detected' if dynamic_params_result else 'Not detected'}")
    console.print(f"[gold1]-------------------------------------------------------[/gold1]")



url_to_check = "google.com"
is_malicious_url(url_to_check)
